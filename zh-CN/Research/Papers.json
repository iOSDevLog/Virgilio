{"## 2019": "## 2019", "* **January - [3D Pose Estimation](https://arxiv.org/pdf/1901.03798.pdf)**": "* ** 1月 -  [3D姿势估算]（https://arxiv.org/pdf/1901.03798.pdf）**", "": "", "A pose estimator takes a video as an input, and outputs a figure that corresponds to the pose of the human individuals present in the video.": "姿势估计器将视频作为输入，并输出与视频中存在的人类个体的姿势相对应的图形。", "Current difficulties with creating a reliable and real-time 3D pose estimator include the fact that there is little training data, alongside the fact that occlusions must be taken to account. For example, if a particular body part is blocked from view, a pose estimator must still be able to infer its position from the position of the rest of the body.": "创建可靠且实时的3D姿势估计器的当前困难包括这样的事实：几乎没有训练数据，以及必须考虑遮挡的事实。例如，如果特定身体部位被阻挡而不能看到，则姿势估计器仍必须能够从身体其余部分的位置推断出其位置。", "This model outperforms all present models as it creates both 2D and 3D representations of the poses. It uses an initial 2D pose estimation, and then utilises a neural network that converts this 2D estimation into a 3D form. It then uses a 3D-to-2D neural network network to convert the pose back into 2D form, which helps to refine the intermediate 3D pose prediction via a self-supervised correction mechanism that can detect the accuracy of the first 2D-to-3D neural network.": "该模型优于所有现有模型，因为它创建姿势的2D和3D表示。它使用初始2D姿态估计，然后利用将该2D估计转换为3D形式的神经网络。然后，它使用3D到2D神经网络网络将姿势转换回2D形式，这有助于通过自我监督校正机制改进中间3D姿势预测，该机制可以检测第一个2D到3D的准确度神经网络。", "The networks allows for the pose estimation to be obtained in about 50 milliseconds, which is nearly 20 frames per second. This is close to real-time, and is suitable for many of the applications of pose estimation.<br/>": "网络允许在大约50毫秒内获得姿势估计，其接近每秒20帧。这接近实时，适用于姿势估计的许多应用", "* **February - [SC-FEGAN: Face-Editing GAN](https://arxiv.org/pdf/1902.06838.pdf)**": "* **二月 -  [SC-FEGAN：面部编辑GAN]（https://arxiv.org/pdf/1902.06838.pdf）**", "This AI is a able to generate realistic images from a set of controllable patterns. It builds on a couple of previous papers in the field - the first is the paper that generates an image from a sparse description (such as a written sentence, and the second is the paper which allows for facial features on images to be customised (such as merging two different faces).": "该AI能够从一组可控模式生成逼真的图像。它建立在该领域以前的几篇论文的基础上 - 第一篇是从稀疏描述中生成图像的纸张（例如书面句子，第二篇是允许定制图像上的面部特征的纸张（例如合并两个不同的面孔）。", "This technique allows us to edit more specific factors - for example, put a smile on someone’s face or remove the sunglasses of an individual. Colour can also be changed - for example, the colour of one’s eye can be manipulated. It is extremely fast, and takes just 50 milliseconds to create these images with 512 x 512 images.": "这种技术允许我们编辑更具体的因素 - 例如，在某人的脸上微笑或删除个人的太阳镜。颜色也可以改变 - 例如，可以操纵一只眼睛的颜色。它非常快，使用512 x 512图像创建这些图像只需50毫秒。", "It has applications in the editing industry in filmmaking, but can also be used by novel consumers who are looking for simple edits to their photos. Though no web app is currently available, it does have its source code publicly-available.": "它在电影制作的编辑行业中有应用，但也可以被寻求对其照片进行简单编辑的新颖消费者使用。虽然目前没有可用的网络应用程序，但它确实公开了其源代码。", "* **February - [Deep Planning Network (PlaNet)](https://www.nature.com/articles/s41467-019-08931-6.pdf)**": "* ** 2月 -  [深度规划网络（PlaNet）]（https://www.nature.com/articles/s41467-019-08931-6.pdf）**", "Google’s PlaNet AI is intended to learn how to plan a sequence of steps that it must take in order to execute a physical goal - for execute, pole balance or walk like a human. The AI must learn in the same manner as a human would - by looking at the pixels of these images (which requires a visual understanding of the context).": "谷歌的PlaNet AI旨在学习如何规划必须采取的一系列步骤，以执行物理目标 - 执行，杆平衡或像人一样行走。 AI必须以与人类相同的方式学习 - 通过查看这些图像的像素（这需要对上下文的视觉理解）。", "The AI uses a sparse reward method, which means that it barely gets feedback with regards to its performance on these tasks. The key difference, however, between this and classical Reinforcement Learning methods is that this AI uses models for its learning. This means that it doesn’t learn every new task from scratch, but rather uses its rudimentary understanding that it has gained from previous activities (such as the nature of gravity), and applies this in future ones. Thus, it has a head-start when learning it a game, making it often 50 times more efficient than techniques that begin with learning from scratch.": "AI使用稀疏奖励方法，这意味着它几乎无法获得有关这些任务的性能的反馈。然而，这与经典的强化学习方法之间的关键区别在于，这种AI使用模型进行学习。这意味着它不是从头开始学习每一项新任务，而是利用它从以前的活动中获得的基本理解（例如引力的性质），并将其应用于未来的任务。因此，它在学习游戏时有一个良好的开端，使其效率通常比从头开始学习的技术高50倍。", "It significantly outperforms other state-of-the-art AI systems in most tasks, such as a cheetah run or human walk. This agent doesn’t require separate training for each activity, as it intermixes its training. Also, it can use just 5 frames of reference for a particular activity in order to learn it, with equates to approximately a fifth of a second of footage. It can then learn how to continue with this activity over a longer period of time.": "它在大多数任务中明显优于其他最先进的AI系统，例如猎豹跑步或人行走。该代理不需要对每项活动进行单独培训，因为它会混合其培训。此外，它可以仅使用5帧参考特定活动来学习它，相当于大约五分之一秒的素材。然后，它可以学习如何在更长的时间内继续此活动。", "* **March - [Humans can decipher adversarial images](https://www.nature.com/articles/s41467-019-08931-6.pdf)**": "* **三月 -  [人类可以破译对抗性图像]（https://www.nature.com/articles/s41467-019-08931-6.pdf）**", "Though recent Convolutional Neural Network systems have surpassed human performance in image detection problems, a problem does remain - simply modifying a pixel or two in the image can cause the system to classify the image as something vastly different. For example, reconfiguring a pixel or two is all it takes for a computer to classify an apple as a car. This ability to ‘fool’ image recognition systems has been criticised as an indication that such systems are unable to interpret images in the same manner as a human would, though a recent paper suggests that this may not be the case.": "虽然最近的卷积神经网络系统在图像检测问题上已超过人类表现，但问题确实存在 - 只需修改图像中的一个或两个像素就可以使系统将图像分类为极为不同的东西。例如，重新配置一两个像素就是计算机将苹果分类为汽车所需的全部内容。这种“愚弄”图像识别系统的能力被批评为这种系统无法以与人类相同的方式解释图像的迹象，尽管最近的一篇论文表明情况可能并非如此。", "In the paper, a pair of cognitive psychologists showed a group of over 1800 subjects images that had already tricked computers into classifying it under the wrong label. They asked people which of two options the computer predicted the object as being - one option being the computer's real conclusion and the other being a random answer. The subjects chose the same answer as computers 75% of the time, and a remarkable 98% of them tended to answer like the computers did.": "在一篇论文中，一对认知心理学家展示了一组超过1800个主题的图像，这些图像已经欺骗了计算机，将其分类为错误的标签。他们问人们计算机预测对象的两种选择中的哪一种 - 一种选择是计算机的真实结论，另一种是随机答案。受试者在75％的时间内选择与计算机相同的答案，其中98％的人倾向于像计算机那样回答。", "Next, the researchers gave subjects a choice between the system’s answer and its next-best guess for images it guessed incorrectly. Once again, the subjects again validated the computer's choices - 91 percent of those tested agreed with the system’s decision.": "接下来，研究人员让受试者在系统的答案和对猜测错误的图像的下一个最佳猜测之间做出选择。再次，受试者再次验证了计算机的选择 -  91％的受试者同意系统的决定。", "The study thus provides a degree of evidence that the apparent flaw with Convolutional Neural Network architectures may not be as bad as many think. It provides a new perspective, along with a new experimental paradigm that can be explored.<br/><br/>": "因此，该研究提供了一定程度的证据表明卷积神经网络架构的明显缺陷可能没有许多人想象的那么糟糕。它提供了一个新的视角，以及一个可以探索的新实验范式。<br/> <br/>", "## 2018": "## 2018", "* **April - [ProGanSR](https://arxiv.org/pdf/1804.02900.pdf)**": "* **四月 -  [ProGanSR]（https://arxiv.org/pdf/1804.02900.pdf）**", "To acheive super-resolution, which allows the conversion of low-resolution images to higher-resolution ones, this paper recommends improving the image resolutions through a progressive method. It takes several intermediate steps where the image produced is slightly better than the predecessor, a known as 'curriculum learning'.": "为了实现超分辨率，允许将低分辨率图像转换为更高分辨率的图像，本文建议通过渐进方法改善图像分辨率。它需要几个中间步骤，其中产生的图像略好于前一个，称为“课程学习”。", "The paper  uses a GAN rather than simply a CNN. Compared to state-of-the-art models, the images produced using the method proposed in this paper are comprehended with a slightly lower accuracy, however they are produced at 5 times the speed.<br/>": "本文使用的是GAN，而不仅仅是CNN。与最先进的模型相比，使用本文提出的方法生成的图像精度略低，但速度是其5倍。", "* **June - [Do CIFAR-10 Classifiers Generalize to CIFAR-10?](https://arxiv.org/pdf/1806.00451.pdf)**": "* ** 6月 -  [CIFAR-10分类器是否适用于CIFAR-10？]（https://arxiv.org/pdf/1806.00451.pdf）**", "The ultimate goal of a Machine Learning model is to predict the output accurately on new, unseen instances. When training a Machine Learning model, it is thus crucial that the test data is not involved in the process of creating the model, as this would introduce bias towards the test set. Unfortunately, we typically have limited access to new data from the same distribution, which results in many researchers today using the test set in place of a validation set. This allows for hyperparameters, such as the learning rate, to be optimised in accordance to the distribution of the selected test set.": "机器学习模型的最终目标是在新的，看不见的实例上准确地预测输出。因此，在训练机器学习模型时，测试数据不参与创建模型的过程至关重要，因为这会给测试集带来偏差。不幸的是，我们通常只能从同一个发行版访问新数据，导致许多研究人员使用测试集代替验证集。这允许根据所选测试集的分布来优化诸如学习速率的超参数。", "The research paper proposes a new test set with about 2000 instances which matches the distribution of the test set for the CIFAR-10 dataset, a well-known dataset that many modern image classifier models are tested on. It then evaluates the performance of 30 different modern image classification models. It finds that there is a significant drop from the accuracy in the original test set to the new test set - for instance, VGG and ResNet architectures drop from their well-established 93% accuracy to about 85%. However, the performance of classifiers relative to one another remains more or less constant - thus, the distribution in performance of classifiers can be considered to simply be horizontally shifted.": "该研究论文提出了一个新的测试集，其中包含大约2000个实例，这些实例与CIFAR-10数据集的测试集的分布相匹配，这是一个众所周知的数据集，许多现代图像分类器模型都经过测试。然后评估30种不同的现代图像分类模型的性能。它发现从原始测试集到新测试集的准确性有显着下降 - 例如，VGG和ResNet架构从其完善的93％精度下降到大约85％。然而，分类器相对于彼此的性能保持或多或少是恒定的 - 因此，分类器的性能分布可以被认为是简单地水平移位。", "The results cast doubt on the robustness of current classifiers. The classification accuracy of widely used models drops significantly - for example, the accuracy loss of VGG and ResNet corresponds to multiple years of progress on the CIFAR-10 dataset. The distribution shift thus questions to what extent current models truly generalise.<br/>": "结果对当前分类器的稳健性产生了怀疑。广泛使用的模型的分类准确性显着下降 - 例如，VGG和ResNet的准确度损失对应于CIFAR-10数据集的多年进展。因此，分配转移质疑当前模型真正推广的程度", "* **June - [RF-Pose](http://rfpose.csail.mit.edu/)**": "* **六月 -  [RF-Pose]（http://rfpose.csail.mit.edu/) **", "The paper provides accurate human pose estimation through walls and occlusions. It leverages the fact that wireless signals in the WiFi frequencies traverse walls and reflect off the human body, and uses a deep neural network approach that parses such radio signals to estimate 2D poses. The pose estimation works well regardless of the lighting conditions, and can also detect multiple humans.": "本文通过墙壁和遮挡提供准确的人体姿势估计。它利用了WiFi频率中的无线信号穿过墙壁并反射出人体的事实，并使用深度神经网络方法来解析这些无线电信号以估计2D姿势。无论光照条件如何，姿势估计都能很好地工作，并且还可以检测多个人。", "In the network, there is a teacher network that looks at the colour image of the wall, and predicts the pose that the human is in. There is also a student network that has the signal as an input, and it learns what the different distributions mean, and how they relate to different human positions and poses. The teacher network shows the student network the correct results, and the student learns how to produce them from radio signals instead of images.": "在网络中，有一个教师网络，可以查看墙壁的彩色图像，并预测人体所处的姿势。还有一个学生网络将信号作为输入，并了解不同的分布意思是，它们与不同的人类姿势和姿势有何关联。教师网络向学生网络显示正确的结果，学生学习如何通过无线电信号而不是图像来制作它们。", "Besides being used for motion capture in interactive video games, as well as helping create special effects for movies, pose estimation can also be used to help detect issues with a patient’s posture, track the activity of animals, understanding sign language and pedestrian activity in self-driving cars.<br/>": "除了用于交互式视频游戏中的动作捕捉，以及帮助为电影创建特殊效果之外，姿势估计还可用于帮助检测患者姿势的问题，跟踪动物的活动，理解手语和自己的行人活动。 - 驾驶汽车。<br/>", "* **July - [Benchmarking Neural Network Robustness to Corruption & Perturbations](https://arxiv.org/pdf/1807.01697.pdf)**": "* ** 7月 -  [基准神经网络对腐败和扰动的稳健性]（https://arxiv.org/pdf/1807.01697.pdf）**", "This paper underlines a method to evaluate the performance of Image Classifiers in terms of their ability to withstand corruptions and perturbations. It creates two datasets - ImageNet-C (for corruptions) and ImageNet-P (for petrurbations) - which help test the robustness of Image Classifiers to such variations, which are common in real-life scenarios.": "本文强调了一种评估图像分类器在抵抗腐败和扰动能力方面的性能的方法。它创建了两个数据集 -  ImageNet-C（用于损坏）和ImageNet-P（用于扰动） - 这有助于测试图像分类器对这种变化的稳健性，这在现实场景中很常见。", "In the context of images, a corruption describes a modification to a base image through distorting its details. The paper utilises 15 different corruption functions on ImageNet mages, each of 5 levels of severity. These corruption functions describe methods including Gaussian Noise, the addition of snow and pixelation.": "在图像的上下文中，损坏通过扭曲其细节来描述对基本图像的修改。本文在ImageNet图像上使用了15种不同的损坏函数，每种函数都有5个严重级别。这些损坏函数描述的方法包括高斯噪声，雪和像素化的添加。", "A perturbation describes the distorting of images by varying its appearance through transformative methods. The paper utilises 8 different perturbation functions on ImageNet images, including zoom, tilt and translation.": "扰动通过变换方法改变其外观来描述图像的扭曲。本文在ImageNet图像上使用了8种不同的扰动函数，包括缩放，倾斜和平移。", "Testing the Classifier with images obtained from the ImageNet-C and ImageNet-P datasets, the paper creates a robustness score regarding a its robustness to both corruption and perturbation by averaging its accuracy over all functions of each type and over all levels of severity.<br/>": "使用从ImageNet-C和ImageNet-P数据集中获得的图像测试分类器，通过在每种类型的所有函数和所有严重级别上平均其准确性，本文创建了关于其对损坏和扰动的鲁棒性的鲁棒性评分。登记/>", "* **July - [Phrank](https://www.nature.com/articles/s41436-018-0072-y)**": "* ** 7月 -  [Phrank]（https://www.nature.com/articles/s41436-018-0072-y）**", "The algorithm produced automates the most labor-intensive part of genetic diagnosis, that of matching a patient’s genetic sequence and symptoms to a disease described in the scientific literature. Without computer help, this match-up process takes 20 to 40 hours per patient - the process involves the expert looking at a list of around 100 of the patient’s suspicious-looking mutations, making an educated guess about which one might cause disease, checking  scientific literature, and then moving on to the next one. The algorithm developed by Bejerano’s team cuts the time needed by 90 percent.": "所产生的算法使基因诊断中最劳动密集的部分自动化，即将患者的基因序列和症状与科学文献中描述的疾病相匹配。如果没有计算机帮助，这个匹配过程每个患者需要20到40个小时 - 这个过程需要专家查看大约100名患者可疑的突变列表，做出有根据的猜测，哪一个可能导致疾病，检查科学文学，然后继续下一个。 Bejerano团队开发的算法将所需时间缩短了90％。", "The algorithm’s name, Phrank, a mashup of “phenotype” and “rank,” gives a hint of how it works: it compares a patient’s symptoms and gene data to a medical-literature knowledge base, and then simply generates a ranked list of which rare genetic diseases are most likely to be responsible for the symptoms. Phrank, on average, ranked the true diagnosis 4th on the list of potential diagnoses it generated.<br/>": "算法的名称，Phrank，一个“表型”和“等级”的混搭，给出了它如何工作的暗示：它将患者的症状和基因数据与医学文献知识库进行比较，然后简单地生成一个排序列表，其中罕见的遗传性疾病最容易引起症状。平均而言，Phrank在其产生的潜在诊断列表中将真正的诊断排在第4位", "* **December - [GAN Dissection](https://arxiv.org/pdf/1811.10597.pdf)**": "* ** 12月 -  [GAN解剖]（https://arxiv.org/pdf/1811.10597.pdf）**", "This paper proposes a framework to o visualise and understand GANs at the unit, object, and scene levels. It provides the ability to generate images of a scene, identify the GAN units or neurons that contribute to a particular object that is part of a scene, and then harness these to either activate or deactivate the presence of that particular object. This thus enables us to manipulate images without the need for tools like Photoshop.": "本文提出了一个框架，用于在单元，对象和场景级别可视化和理解GAN。它提供了生成场景图像，识别对作为场景一部分的特定对象有贡献的GAN单元或神经元的能力，然后利用这些来激活或停用该特定对象的存在。因此，这使我们能够在不需要Photoshop等工具的情况下操作图像。", "For example, if we had an image of a church, we could indicate to this framework that we wished to remove the doors present in the image. The framework would thus remove the doors while maintaining the structure of the rest of the image in a suitable manner. We could then add the doors back, if desired. On top of this, we can select a particular region of an image where we wish to add something new - for example, I could add a tree to the right side of the image of a church. The framework understands that the trees have a root in the ground, and thus builds on from the ground up in the specified location. The framework is further able to recognise where additions are not suitable - for example, if we wished to draw a door in the sky, the framework would not accept this request.": "例如，如果我们有一个教堂的图像，我们可以向这个框架表明我们希望移除图像中存在的门。因此，框架将移除门，同时以合适的方式保持图像的其余部分的结构。如果需要，我们可以将门添加回去。除此之外，我们可以选择图像的特定区域，我们希望在其中添加新内容 - 例如，我可以在教堂图像的右侧添加一棵树。框架理解树木在地面上有根，因此在指定位置从地面构建。该框架还能够识别添加不适合的地方 - 例如，如果我们希望在天空中绘制一扇门，框架将不接受此请求。", "The framework uses a segmentation network along with a dissection method to identify the individual units of the generator that match meaningful object classes, like trees. It then activates and deactivates the neurons corresponding to each object class when they are modified in the image - for example, inserting a tree activates the neurons in the GAN that corresponds to a tree. What allows this is a key finding in the paper - the same neurons control a specific object class in a variety of contexts, even if the final appearance of the object varies tremendously. The same neurons can switch on the concept of a \"door\" even if a big stone wall requires a big heavy door facing to the left, or a little hut requires a small curtain door facing to the right.<br/>": "该框架使用分段网络和解剖方法来识别与有意义的对象类（如树）匹配的生成器的各个单元。然后，当它们在图像中被修改时，它激活和停用对应于每个对象类的神经元 - 例如，插入树激活GAN中与树对应的神经元。什么允许这是本文的一个重要发现 - 相同的神经元控制各种环境中的特定对象类，即使对象的最终外观变化很大。相同的神经元可以打开“门”的概念，即使一个巨大的石墙需要一个朝向左侧的大型重型门，或者一个小小屋需要一个面向右侧的小型门帘。", "* **December - [Style-Based Generator](https://arxiv.org/pdf/1812.04948.pdf)**": "* ** 12月 -  [基于样式的生成器]（https://arxiv.org/pdf/1812.04948.pdf）**", "This research paper, authored by scientists at processor and graphics card company Nvidia, demonstrates the potential of an alternative generator architecture for generative adversarial networks that borrows from style transfer literature. It allows for specific customisation and control over features within a human face. It has the potential to be applied to other fields, and has thus far been tested successfully on cars and rooms.": "这篇由处理器和显卡公司Nvidia的科学家撰写的研究论文展示了从样式转移文献中借鉴的生成对抗网络的替代生成器架构的潜力。它允许对人脸中的特征进行特定的定制和控制。它有可能应用于其他领域，迄今已在汽车和房间上成功测试过。", "The generator can combine different aspects of images. For example, if one wished to overlay the gender of one face with the face of another, the generator can do so. The aspects that can be transferred include gender, hair length, pose and the presence of glasses.": "生成器可以组合图像的不同方面。例如，如果希望将一个面部的性别与另一个面部的性别重叠，则生成器可以这样做。可以转移的方面包括性别，头发长度，姿势和眼镜的存在。", "The parameters of the generator can also be controlled one by one without modifying the core content of an image. For example, the presence of a stubble can be modified.": "还可以逐个控制发生器的参数而不修改图像的核心内容。例如，可以修改残茬的存在。", "The generator can also perform interpolation. This means that if we have two images A and B, the generator can create intermediate images that map one to another. It can even change the gender in the process. All intermediate images look real too.<br/><br/>": "生成器也可以执行插值。这意味着如果我们有两个图像A和B，则生成器可以创建将这些图像映射到另一个的中间图像。它甚至可以改变过程中的性别。所有中间图像也都是真实的。<br/> <br/>", "## 2017": "## 2017", "* **April - [Federatred Learning](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html?utm_campaign=the_algorithm.unpaid.engagement&utm_source=hs_email&utm_medium=email&utm_content=70607703&_hsenc=p2ANqtz-9kYBnRclCyRm1_Fweb9tezCh4VeAFJVZTpjvf-fzz2akkq4AGCU5Uhhv-4ApNIZO7vb2ZpigcgT_lU3E_2sF1mtaZzqg&_hsmi=70607705)**": "* **四月 -  [Federatred Learning]（https://ai.googleblog.com/2017/04/federated-learning-collaborative.html?utm_campaign=the_algorithm.unpaid.engagement&utm_source=hs_email&utm_medium=email&utm_content=70607703&_hsenc=p2ANqtz-9kYBnRclCyRm1_Fweb9tezCh4VeAFJVZTpjvf- fzz2akkq4AGCU5Uhhv-4ApNIZO7vb2ZpigcgT_lU3E_2sF1mtaZzqg＆_hsmi = 70607705）**", "A big problem being faced by organisations working with developing Machine Learning algorithms and systems today regards privacy - consumers are unwilling to allow their data to be viewed by others, as this data is considered sensitive to them. Google AI's new research on Federated Learning proposes a solution to this.": "当今开发机器学习算法和系统的组织面临的一个大问题是隐私 - 消费者不愿意让他人查看他们的数据，因为这些数据被认为对他们敏感。 Google AI对联合学习的新研究提出了一个解决方案。", "The Federated Learning technique relies on distributed training - it allows for models to be trained independently on a subset of the universal data, and then assembles these independent models into a single, master model.": "联邦学习技术依赖于分布式训练 - 它允许在通用数据的子集上独立训练模型，然后将这些独立模型组装成单个主模型。", "There are a couple of use cases for this to better describe how it functions. Firstly, say medical patients are unwilling to have their health records be sent to other hospitals and organisations who they cannot trust. Federated Learning suggests that each hospital construct its own model using the limited patient data that it has, and then it assembles the models of each hospital into a single, unified model using Google's Federated Averaging algorithm. Secondly, say that we wish to train a predictive keyboard to be uniquely suited to our personal typing patterns on our smartphone. We can use a Federated model, which has been trained and compiled from the predictive patterns of many different users and their data, and then pass in our own personal keyboard typing data to update the model to be better suited to our personal typing habits.": "有几个用例可以更好地描述它的功能。首先，医疗患者不愿意将他们的健康记录发送给他们不能信任的其他医院和组织。 Federated Learning建议每家医院使用其拥有的有限患者数据构建自己的模型，然后使用Google的联合平均算法将每个医院的模型组装成单个统一模型。其次，假设我们希望训练一个预测键盘，以便在我们的智能手机上独特地适合我们的个人打字模式。我们可以使用Federated模型，该模型已经根据许多不同用户及其数据的预测模式进行了训练和编译，然后传递我们自己的个人键盘输入数据以更新模型以更好地适应我们的个人打字习惯。", "Federated Learning technqiues have seen many updates and improvements since, and will certainly remain relevant as AI enters a privacy-centered time in its development.<br/>": "联邦学习技术自那时起就经历了许多更新和改进，并且当人工智能在其开发过程中进入以隐私为中心的时代时，它肯定会保持相关性。", "* **September - [Deep Feature Consistent Deep Image Transformations (DFC-DIT)](https://arxiv.org/pdf/1707.09482.pdf)**": "* **九月 -  [深度特征一致的深度图像转换（DFC-DIT）]（https://arxiv.org/pdf/1707.09482.pdf）**", "Say you need to downscale an image of yours without reducing the accuracy of the main features, or if you wished to remove RGB colours from an image, or if you display an image of high dynamic range on a screen that doesn’t support the range. Though there are hundreds of existing structures that do these, this paper describes a method that does these exceptionally well in comparison to current methods.": "假设您需要缩小您的图像而不降低主要功能的准确性，或者您希望从图像中删除RGB颜色，或者如果您在不支持该范围的屏幕上显示高动态范围的图像。虽然有数百个现有结构可以做到这些，但本文描述了一种方法，与现有方法相比，这些结构非常好。", "The paper suggests a Deep Feature Consistent Deep Image Transformation (DFC-DIT) framework. It utilises a Convolutional Neural Network (CNN) that produces three outputs for an input image - a downscaled version, a decolorised version and a HDR tone mapped version. It also uses another pretrained and fixed deep CNN that employs the deep feature consistency principle - this ensures that all main features are preserved in the image.<br/>": "本文提出了深度特征一致的深度图像变换（DFC-DIT）框架。它利用卷积神经网络（CNN）为输入图像生成三个输出 - 缩小版本，脱色版本和HDR色调映射版本。它还使用了另一种采用深度特征一致性原理的预训练和固定深度CNN  - 这确保了所有主要特征都保留在图像中。<br/>"}
